/*
 * Copyright (c) 2020, Yanhui Shi <lime.syh at gmail dot com>
 * All rights reserved.
 *
 * Permission to use, copy, modify, and/or distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "platform.h"
#include <assert.h>
#include <stddef.h>
#include "core.h"
#include "proc.h"
#include "scheduler.h"

static_assert(offsetof(csp_proc_t, mxcsr) == 0x18, "csp_proc_t.mxcsr offset mismatch");
static_assert(offsetof(csp_proc_t, rsp) == 0x20, "csp_proc_t.rsp offset mismatch");
static_assert(offsetof(csp_proc_t, rbp) == 0x28, "csp_proc_t.rbp offset mismatch");
static_assert(offsetof(csp_proc_t, registers.callee_saved.rbx) == 0x30, "csp_proc_t.rbx offset mismatch");
static_assert(offsetof(csp_proc_t, registers.caller_saved.rdi) == 0x30, "csp_proc_t.rdi offset mismatch");

/* Total processes generated by libcsp plugin. */
extern size_t csp_procs_num;
/* Process size generated by libcsp plugin which is guaranteed to be 4k-bytes
 * alignment. */
extern size_t csp_procs_size[];

extern _Thread_local csp_core_t *csp_this_core;

#ifndef csp_with_sysmalloc
extern void *csp_mem_alloc(size_t pid, size_t size);
extern void csp_mem_free(size_t pid, void *obj);
#endif

csp_proc_t *csp_proc_new(int id, bool waited_by_parent) {
  csp_core_t *this_core = csp_this_core;
  size_t size = csp_procs_size[id];

#ifdef csp_with_sysmalloc
  uintptr_t base = (uintptr_t)malloc(size);
#else
  uintptr_t base = (uintptr_t)csp_mem_alloc(this_core->pid, size);
#endif

  if (base == (uintptr_t)NULL) {
    perror("libcsp failed to alloc new proc.");
    exit(EXIT_FAILURE);
  }

  csp_proc_t *proc = (csp_proc_t *)(base + size - sizeof(csp_proc_t));
  proc->base = base;
  proc->is_new = true;
  proc->borned_pid = this_core->pid;
  atomic_store(&proc->stat, csp_proc_stat_none);

  /* We should make sure %rbp is 16-bytes alignment. */
  proc->rbp = (uintptr_t)proc - (!!((uintptr_t)proc & 0x0f) << 3);

  proc->nchild = 0;
  if (waited_by_parent) {
    proc->parent = (struct csp_proc_s *)this_core->running;
  } else {
    proc->parent = NULL;
  }
  proc->pre = proc->next = NULL;

#ifdef csp_enable_valgrind
  proc->valgrind_stack = VALGRIND_STACK_REGISTER(proc->base, proc);
#endif

  if (csp_global_scheduler) {
    atomic_fetch_add(&csp_global_scheduler->num_procs, 1);
  }

  return proc;
}

__attribute__((noinline,used)) void csp_proc_nchild_set(size_t nchild) {
  atomic_store(&((csp_proc_t *)csp_this_core->running)->nchild, nchild);
}

__attribute__((naked)) void csp_proc_restore(csp_proc_t *proc) {
  __asm__ __volatile__(
    "ldmxcsr 0x18(%rdi)\n"
    "fldcw   0x1c(%rdi)\n"

    /* Load `is_new` and check it. */
    "mov  0x10(%rdi), %rax\n"
    "test %rax, %rax\n"
    "jz  normal_restore@plt\n"
    "cmp $1, %rax\n"
    "je  new_restore@plt\n"
    "cmp $2, %rax\n"
    "je  preempt_restore@plt\n"

    "normal_restore:\n"
    "mov     0x20(%rdi), %rsp\n"
    "mov     0x28(%rdi), %rbp\n"
    "mov 0x30(%rdi), %rbx\n"
    "mov 0x38(%rdi), %r12\n"
    "mov 0x40(%rdi), %r13\n"
    "mov 0x48(%rdi), %r14\n"
    "mov 0x50(%rdi), %r15\n"
    "retq\n"

    "new_restore:\n"
    "movq $0, 0x10(%rdi)\n" // Set `is_new` to 0.
    "mov     0x20(%rdi), %rsp\n"
    "mov     0x28(%rdi), %rbp\n"
    "mov 0x38(%rdi), %rsi\n"
    "mov 0x40(%rdi), %rdx\n"
    "mov 0x48(%rdi), %rcx\n"
    "mov 0x50(%rdi), %r8\n"
    "mov 0x58(%rdi), %r9\n"
    "mov 0x30(%rdi), %rdi\n" // Restore %rdi at the last step.
    "retq\n"

    "preempt_restore:\n"
    "movq $0, 0x10(%rdi)\n" // Set `is_new` to 0.
    "mov     0x20(%rdi), %rsp\n"
    "pop %r15\n"
    "pop %r14\n"
    "pop %r13\n"
    "pop %r12\n"
    "pop %r11\n"
    "pop %r10\n"
    "pop %r9\n"
    "pop %r8\n"
    "pop %rbp\n"
    "pop %rdi\n"
    "pop %rsi\n"
    "pop %rdx\n"
    "pop %rcx\n"
    "pop %rbx\n"
    "pop %rax\n"
    "retq\n"
  );
}

extern void csp_preempt_helper(uintptr_t sp);

__attribute__((naked)) void csp_async_preempt(void) {
    __asm__ __volatile__(
        "push %rax\n"
        "push %rbx\n"
        "push %rcx\n"
        "push %rdx\n"
        "push %rsi\n"
        "push %rdi\n"
        "push %rbp\n"
        "push %r8\n"
        "push %r9\n"
        "push %r10\n"
        "push %r11\n"
        "push %r12\n"
        "push %r13\n"
        "push %r14\n"
        "push %r15\n"
        "mov %rsp, %rdi\n"
        "and $-16, %rsp\n"
        "jmp csp_preempt_helper@plt\n"
    );
}

__attribute__((noinline)) void csp_proc_destroy(csp_proc_t *proc) {
  if (csp_global_scheduler) {
      atomic_fetch_sub(&csp_global_scheduler->num_procs, 1);
  }

#ifdef csp_enable_valgrind
  VALGRIND_STACK_DEREGISTER(proc->valgrind_stack);
#endif

#ifdef csp_with_sysmalloc
  free((void *)proc->base);
#else
  csp_mem_free(proc->borned_pid, (void *)proc->base);
#endif
}
